<p>the project</p>
<p>The goal of our project is to set up an end-to-end MLOps pipeline for a binary CNN Classifier for classifying pneumonia from chest X-ray images. This includes git workflow, version control, experiment reproducibility and cloud service. We will have an overall focus on good code practice, pytorch and monitoring the model. Our end result will be a successfully deployed CNN model, whose training has been properly logged, and finally, containerized and uploaded using docker.</p>
<h3>What framework are you going to use, and you do you intend to include the framework into your project?</h3>
<p>For the model development we will use pytorch as the primary deep learning framework, due to its flexibility and strong ability for computer vision tasks. Image preprocessing and augmentation will be handled by PyTorch/vision.
We envision setting up the framework as part of our environment, while writing and maintaining an organized structured code with version control. We are considering using the pytorch lightning framework, in order to boilerplate the training loop and hopefully make our model run faster</p>
<h3>What data are you going to run on (initially, may change)</h3>
<p>The project will use the Chest X-Ray Pneumonia dataset, which contains 5,893 X-ray images (1240 × 840) categorized as either Pneumonia or Normal; with predefined test, training and validation splits of independent patients. The dataset is well-suited for this project due to its manageable size and relevance of robust deployment and monitoring in the medical domain.</p>
<h3>What models do you expect to use</h3>
<p>We expect to use a Convolution Neural Network (CNN) for the classification of the images. Beginning with a simple CNN as a baseline, as to establish a reference-level of performance. We will implement transfer learning, by loading pre-trained weights for the first layers and then fine tune the following layers for our assignment in hand. We will apply a handful of different CNN architectures such as alexNet and VGGNET 16 and then use the respective model in our configuration.</p>
<h2>Project structure</h2>
<p>The directory structure of the project looks like this:
<code>txt
├── .github/                  # Github actions and dependabot
│   ├── dependabot.yaml
│   └── workflows/
│       └── tests.yaml
├── configs/                  # Configuration files
├── data/                     # Data directory
│   ├── processed
│   └── raw
├── dockerfiles/              # Dockerfiles
│   ├── api.Dockerfile
│   └── train.Dockerfile
├── docs/                     # Documentation
│   ├── mkdocs.yml
│   └── source/
│       └── index.md
├── models/                   # Trained models
├── notebooks/                # Jupyter notebooks
├── reports/                  # Reports
│   └── figures/
├── src/                      # Source code
│   ├── project_name/
│   │   ├── __init__.py
│   │   ├── api.py
│   │   ├── data.py
│   │   ├── evaluate.py
│   │   ├── models.py
│   │   ├── train.py
│   │   └── visualize.py
└── tests/                    # Tests
│   ├── __init__.py
│   ├── test_api.py
│   ├── test_data.py
│   └── test_model.py
├── .gitignore
├── .pre-commit-config.yaml
├── LICENSE
├── pyproject.toml            # Python project file
├── README.md                 # Project README
├── requirements.txt          # Project requirements
├── requirements_dev.txt      # Development requirements
└── tasks.py                  # Project tasks</code></p>
<p>Created using <a href="https://github.com/SkafteNicki/mlops_template">mlops_template</a>,
a <a href="https://github.com/cookiecutter/cookiecutter">cookiecutter template</a> for getting
started with Machine Learning Operations (MLOps).</p>
